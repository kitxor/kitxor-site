<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How Diffusion Models Actually Work ~ kitxor</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Courier New', Courier, monospace;
            background: #ffffff;
            color: #000000;
            padding: 30px 20px;
            line-height: 1.5;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        .back-link {
            color: #0066cc;
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 20px;
            display: inline-block;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        .back-link::before {
            content: '← ';
        }

        .post-header {
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 2px solid #000000;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 8px;
            color: #000000;
        }

        .post-meta {
            color: #666666;
            font-size: 0.85rem;
        }

        .content {
            color: #000000;
        }

        h2 {
            color: #000000;
            font-size: 1.5rem;
            margin-top: 30px;
            margin-bottom: 12px;
            border-left: 3px solid #000000;
            padding-left: 10px;
        }

        h3 {
            color: #000000;
            font-size: 1.2rem;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        p {
            margin-bottom: 12px;
        }

        code {
            background: #f0f0f0;
            color: #000000;
            padding: 2px 6px;
            border-radius: 3px;
            font-size: 0.9rem;
        }

        pre {
            background: #f9f9f9;
            border: 1px solid #cccccc;
            border-radius: 4px;
            padding: 15px;
            overflow-x: auto;
            margin: 15px 0;
        }

        pre code {
            background: none;
            padding: 0;
            color: #000000;
            display: block;
        }

        ul, ol {
            margin: 12px 0;
            padding-left: 40px;
        }

        li {
            margin-bottom: 6px;
        }

        a {
            color: #0066cc;
            text-decoration: underline;
        }

        a:hover {
            color: #004499;
        }

        @media (max-width: 600px) {
            body {
                padding: 20px 15px;
            }

            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.3rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="../index.html" class="back-link">back to home</a>

        <div class="post-header">
            <h1>How Diffusion Models Actually Work</h1>
            <div class="post-meta">2026-01-11 | machine learning, diffusion models, stable diffusion</div>
        </div>

        <div class="content">
            <p>The core loop is simple:</p>

            <p>Take static noise + prompt → feed to Neural Network → NN predicts the noise → subtract it → get a slightly less noisy image.</p>

            <p>Repeat this loop N times. Each pass removes a bit more noise. At the end, you have a clean image.</p>

            <h2>How the NN learns this</h2>

            <p>During training, the model sees millions of images with noise added at various levels. Its only job: predict what noise was added. Do this enough times, and the NN gets really good at spotting noise in any image.</p>

            <h2>Inference is just training in reverse</h2>

            <p>Start with pure noise. The NN predicts what noise it sees. Subtract that. Now you have a slightly less noisy image. The prompt steers which noise patterns get predicted—ask for "cat" and the NN predicts noise that, when removed, reveals cat-like shapes.</p>

            <h2>Why latent space matters</h2>

            <p>Running this loop on a 512×512 image directly would melt your VRAM. So instead, we compress everything to a smaller "latent" representation (like 64×64), run the denoising loop there, then scale back up to full resolution at the end. This is why it's called Latent Diffusion.</p>

            <h2>The practical bit</h2>

            <p>Stable Diffusion is the most consumer-friendly implementation of this. Runs on regular GPUs, massive community, tons of fine-tuned models. If you have a GPU with 8-12GB VRAM, you can run this locally for free.</p>

            <h2>Key Takeaways</h2>
            <ul>
                <li>Core loop: noise + prompt → predict noise → subtract → repeat N times</li>
                <li>Training teaches the NN to recognize noise patterns at all levels</li>
                <li>Prompts steer which noise patterns get predicted and removed</li>
                <li>Latent space compression (512×512 → 64×64) makes it GPU-friendly</li>
                <li>Stable Diffusion runs locally on 8-12GB VRAM consumer GPUs</li>
            </ul>

            <div style="margin-top: 40px; padding-top: 15px; border-top: 2px solid #000000; text-align: center;">
                <a href="../index.html" class="back-link">back to all posts</a>
            </div>
        </div>
    </div>
</body>
</html>
